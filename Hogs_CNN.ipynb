{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfedacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imported PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "# All images stored in CNN_Data/CNN\n",
    "# Collected by Carlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee22950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# A generic resizing function that resizes images appropriately in 500 x 500\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((500, 500)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4b53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# # Adjust dataset based upon specifications of the project.\n",
    "dataset = datasets.ImageFolder('CNN_Data/CNN', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf6a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 classes: ['official_razorback', 'other']\n",
      "Total images: 62\n"
     ]
    }
   ],
   "source": [
    "# Clara\n",
    "# Grab number of classes within the dataset based on the directory structure\n",
    "num_classes = len(dataset.classes)\n",
    "print(f\"{num_classes} classes: {dataset.classes}\")\n",
    "print(f\"Total images: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a123523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# Utilizing an 80/20 training-test split, mostly because of the small dataset size.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da050c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# Create dataloaders based on the train and test datasets.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 49\n",
      "Testing images: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clara\n",
    "# Print the quantities of images.\n",
    "# Training is super close to 50, which is nice.\n",
    "print(f\"Training images: {train_size}\")\n",
    "print(f\"Testing images: {test_size}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# Define baseline CNN moddel. No frills.\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Layer 1: Find basic features (edges, colors)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Layer 2: Find more complex patterns\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Layer 3: Find even more detail\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Layer 4: Combine everything to make predictions\n",
    "        self.fc1 = nn.Linear(128 * 62 * 62, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Dropout to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through conv layer 1\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 500->250\n",
    "        \n",
    "        # Pass through conv layer 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 250->125\n",
    "        \n",
    "        # Pass through conv layer 3\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 125->62\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 128 * 62 * 62)\n",
    "        \n",
    "        # Final classification layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# Create the model\n",
    "model = SimpleCNN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55cd4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Clara\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bc86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc741a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train(num_epochs=10):\n",
    "    # Train CNN\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_num, (images, labels) in enumerate(train_loader):\n",
    "            # Move data to GPU/CPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clear previous gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Make predictions\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track accuracy\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Print results for this epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 10.2388, Train Accuracy: 55.10%\n",
      "Epoch 2/10 - Train Loss: 6.7047, Train Accuracy: 48.98%\n",
      "Epoch 3/10 - Train Loss: 1.1226, Train Accuracy: 53.06%\n",
      "Epoch 4/10 - Train Loss: 0.6663, Train Accuracy: 65.31%\n",
      "Epoch 5/10 - Train Loss: 1.2833, Train Accuracy: 55.10%\n",
      "Epoch 6/10 - Train Loss: 0.8298, Train Accuracy: 65.31%\n",
      "Epoch 7/10 - Train Loss: 0.5729, Train Accuracy: 71.43%\n",
      "Epoch 8/10 - Train Loss: 0.5224, Train Accuracy: 63.27%\n",
      "Epoch 9/10 - Train Loss: 0.4129, Train Accuracy: 75.51%\n",
      "Epoch 10/10 - Train Loss: 0.3917, Train Accuracy: 87.76%\n"
     ]
    }
   ],
   "source": [
    "# Clara\n",
    "# Train the model. Observe that the accuracies aren't bad.\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe456b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clara\n",
    "# Test model now.\n",
    "def test():\n",
    "\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(\"Test:\")\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Correct: {correct}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09351abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "Test Loss: 0.7001\n",
      "Test Accuracy: 38.46%\n",
      "Correct: 5/13\n"
     ]
    }
   ],
   "source": [
    "# Clara\n",
    "# Test\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406ef6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
